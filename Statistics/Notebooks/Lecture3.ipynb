{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3: Model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Correlation is a simple case of model building\n",
    "\n",
    "When computing the correlation between two variables $x$ and $x$, we are implicitly fitting the linear model $y = ax+b$ where $a$ and $b$ are free parameters. \n",
    "\n",
    "We can say that $x$ is an $input variable$, $y$ is the $output variable$, and the model attempts to predict the output variable based on the input variable. \n",
    "\n",
    "Alternatively, we can say that $x$ is a $regressor$, $y$ is the $data$, and the model attempts to explain the data using the $regressor$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link between correlation and linear models can be understood as follows:\n",
    "\n",
    "- after $z$-scoring (https://en.wikipedia.org/wiki/Standard_score) each variable, the slope of the line that best predicts $y$ from $x$ is equal to the correlation value $r$.\n",
    "\n",
    "- Thus, correlation is a simple case of model building in which we use a linear model to predict one variable based on another. But what if we have more than one input variable? Or what if the phenomenon we are trying to model is nonlinear? To tackle these cases, we must obtain a more explicit understanding of model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Overview of model building\n",
    "\n",
    "To keep thins simple, it is useful to break down model building into four distinct issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model specification** refers to choosing the specific type of model to apply to the data. For example, do we use a simple linear model or a complicated nonlinear model? (In this case of correlation, a linear model is implicitly being applied).\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model fitting** refers to estimating the free parameters of a given model based on the observed data. (In the case of correlation, the parameter of interest, $r$, is computed through a simple sequence of mathematical operations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model accuracy** refers to quantifying how well a fitted model describes the data. The tricky issue here is the potential for a model to overfit the data. (In the case of correlation, the analogue of model accuracy is $r^2$ as it indicates the amount of variance in one variable that can be explained by the other.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model reliability** refers to quantifying the reliability of the parameters of a fitted model. In other words, how confident we are with regards to the parameters we have estimated from the data? (In the case of correlation, the analogue of model reliability is the sampling error on $r$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Supervised vs. unsupervised learning\n",
    "\n",
    "Statistical models can be broadly divided into models that can be used to perform *supervised learning* and models that can be used to perform *unsupervised learning*. The idea behind learning is that by applying a model to data, we learn something about those data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **supervised** learning (e.g. linear regression), we are trying to learn the mapping between one or more input variables and an output variable. The problem is supervised in the sense that we observe both the input and the output and the goal is clearly defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **unsupervies** learning (e.g. PCA, cluster analysis), we are trying to learn the structure in a given set of data. The problem is unsupervised in the sense that we observer only a single set of data and there is no clearly defined, explicit goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who are fluent in probability theory, supervised learning can be viewed as characterizing $p(y|x)$, that is, the probability of output $y$ given input $x$, whereas unsuperviesd learning can be viewed as characterizing $p(x)$, that is, the probability distribution underlying a set of inputs $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression vs Classification\n",
    "\n",
    "Both regression and classification involve using one or more input variables to predict an output variable. In terms of the problem specification, the only difference between regression and classification is the nature of the output variable.\n",
    "\n",
    "If the output variable is continuous, the problem is known as **regression**.  \n",
    "IF the output variable is discrete, the problem is known as **classification**\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But regression and classification have diffirent technical details.  \n",
    "Below are diffirent regression model types describtion:\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Linear models\n",
    "\n",
    "**Linear models** are models in which the prediction is a weighted sum of the regressors. For example, suppose we have regressors $x_i$ where $i$ ranges from 1 to $n$.\n",
    "\n",
    "The prediction of a linear model is \n",
    "\n",
    "$$y = \\sum_{i=1}^{n}w_ix_i$$\n",
    "\n",
    "where $w_i$ is the weight on the $i$-th regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why $y=ax+b$ counts as a linear model, notice that we can re-write the model as $y=ax+b1$ where 1 is a constant regressor consisting of all ones. Then, if we set $x_1 = x$ and $x_2=1$, the model can be re-written as:\n",
    "\n",
    "$$y = w_1x_1+w_2x_2$$\n",
    "\n",
    "where $w_1$,$w_2$ are free parameters.  \n",
    "Linear models are easy to understand and easy to fit. However, not all phenomena are linear.\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Nonlinear models\n",
    "\n",
    "$Nonlinear models$ are models in which the prediction cannot be expressed as a weighted sum of the regressors. It can be divided into three types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Linearized models\n",
    "\n",
    "Linearized models are the same as linear models expect that the input space has been expanded using nonlinear functions (e.g. polunomials, Gaussians, sinusoids).\n",
    "\n",
    "For example, suppose we start with the linear model $y=ax+b$ where $a$ and $b$ are free parameters. If we expand the input space to include a new regressor $x^2$, we obtain the model $y=ax^2 + bx + c$ where $a,b,c$ are free parameters.\n",
    "\n",
    "This new model is nonlinear because the prediction of the model is not linear with respect to $x$. However, the new model can be viewed as a linear model with respect to an input space consisting of three regressors \n",
    "\n",
    "$$x_1 = x^2$$\n",
    "$$x_2 = x$$\n",
    "$$x_3 = 1$$\n",
    "\n",
    "\n",
    "Linearized models are as easy to understand and fit as linear models, and has the additional denefit of being able to characterize nonlinear phenomena.\n",
    "\n",
    "However, for any given problem, it is not clear $a priori$ exactly what type of nonlinear functions to add into the input space.\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Parametric nonlinear models\n",
    "\n",
    "Parametric nonlinear models can be thought of as any model that can be written down using mathematical operations but which cannot be expressed as a linearized model\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key characteristic of linearized models is that they are linear with respect to the free parameters in the models.   \n",
    "Parametric nonlinear models **DO NOT HAVE** this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider the model $y=x^n$ where $n$ is a free parameter. The output of this model is not linear with respect t o$n$ (there is no way to express $x^n$ as $an+b$ where $a$ and $b$ are weights). This the modewl does not count as a linearized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametric nonlinear models are easy to understand and can characterize nonlinear phenomena. However, they are tricky to fit given that they are nonlinear with respect to the free parameters (e.g. risk of local minima)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Nonparametric nonlinear models\n",
    "\n",
    "Nonparametric nonlinear models are essentially very flexible nonlinear models that can be generically applied to arbitrary datasets.\n",
    "\n",
    "The destintion between nonparametric nonlinear models and the other types of nonlinear models can be hazy, but we can make some generalities:\n",
    "\n",
    "1. Nonparametric nonlinear models are sometimes nonlinear with respect to the free parameters\n",
    "\n",
    "2. Nonparametric nonlinear models make few assumptions on the form of the nonlinearity of the model, unlike parametric nonlinear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of nonparametric nonlinear models include **nearest-neghbor methods** ( predict the output based on the nearest input sample), **local regression** (fit a simple model at each point in the input space based on nearby data points), and **neural networks** (use generic basis functions such as sigmoidal or radial basis functions to model the output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric nonlinear models are flexible and powerful and, in some cases, can also be simple and elegant.  \n",
    "\n",
    "However, the fitted may be difficult to interpret and may suffer from overfitting and local minima. Also, the computational complexity of nonparametric nonlinear models often grows with the size of the dataset and may therefore pose practical problems.\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Summary of model types\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Matrix representation of linear models\n",
    "\n",
    "![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All linear (and linearized) models can be expressed as a weighted sum of one or more fixed regressors. We can formally represent thus using matrix notation:\n",
    "\n",
    "$$y=XW+n$$\n",
    "\n",
    "where $y$ is a set of data points ($n*1$), $X$ is a set of regressors ($n*p$), $W$ is a set of weights ($p*1$), and $n$ is a set of residuals ($n*1$).\n",
    "\n",
    "\n",
    "Note that compared to previous formulations of linear models, we are now explicitly including a term for the residuals. The residuals are simply difference between the data ($y$) and the model fit ($XW$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Variance score: 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
