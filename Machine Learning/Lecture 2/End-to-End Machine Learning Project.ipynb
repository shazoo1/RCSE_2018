{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main steps in ML project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Look at the big picture\n",
    "2. Get the data\n",
    "3. Discover and visualize the data to gain insights\n",
    "4. Prepare the data for Machine Learning algorithms\n",
    "5. Select a model and train it\n",
    "6. Fine-tune your model\n",
    "7. Present your solution\n",
    "8. Launch, monitor, and maintain your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://registry.opendata.aws/\n",
    "- https://www.kaggle.com/datasets\n",
    "- http://archive.ics.uci.edu/ml/index.php\n",
    "- http://dataportals.org/\n",
    "- https://opendatamonitor.eu/frontend/web/index.php?r=dashboard%2Findex\n",
    "- https://www.quandl.com/\n",
    "- https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Project checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Frame the problem and look at the big picture\n",
    "    - Define the objective in business terms\n",
    "    - How will your solution be used?\n",
    "    - What are the current solutions/workarounds (if any)?\n",
    "    - How should you frame this problem (supervised/unsupervised, online/offline, etc.)?\n",
    "    - How should perfomance be measured?\n",
    "    - Is the performance measure aligned with the business objective?\n",
    "    - What would be the minimum performance needed to reach the business objective?\n",
    "    - What are comparable problems? Can you reuse experience or tools?\n",
    "    - Is human expertise available?\n",
    "    - How would you solve the problem manually?\n",
    "    - List the assumptions you (or others) have made so far.\n",
    "    - Verify assumptions if possible.\n",
    "2. Get the data\n",
    "    - List the data you need and how much you need\n",
    "    - Find and document where you can get that data\n",
    "    - Check how much space it will take\n",
    "    - Check legal obligations, and get authorization if necessary\n",
    "    - Get access authorizations\n",
    "    - Create a workspace (with enough storage space)\n",
    "    - Get the data\n",
    "    - Convert the data to a format you can easily manipulate (without changing the data itself).\n",
    "    - Ensure sensitive information is deleted or protected (e.g. anonymized)\n",
    "    - Check the size and type of data (time series, sample, geographical, etc.)\n",
    "    - Sample a test set, put it aside, and never look at it (no data snooping!).\n",
    "3. Explore the data to gain insights\n",
    "    - Create a copy of the data for exploration (sampling it down to a manageable size if necessary)\n",
    "    - Create a notebook to keep your exploration\n",
    "    - Study each attribute and its characteristics:\n",
    "        * Name\n",
    "        * Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n",
    "        * % of missing values\n",
    "        * Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
    "        * Possibly useful for the task?\n",
    "        * Type of distribution (Gaussian, uniform, logarithmic, etc.)\n",
    "        * For supervised learning tasks, identify the target attribute(s).\n",
    "        * Visualize the data.\n",
    "        * Study the correlations between attributes.\n",
    "        * Study how you would solve the problem manually\n",
    "        * Identify the promising transformations you may want to apply.\n",
    "        * Identify extra data that would be useful.\n",
    "        * Document what you have learned.\n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms\n",
    "    - Work on copies of the data (keep the original dataset intact)\n",
    "    - Write functions for all data transofrmations you apply, for five reasons:\n",
    "        * So you can easily prepare the data the next time you get a fresh dataset\n",
    "        * So you can apply these transformations in future projects\n",
    "        * To clean and prepare the test set\n",
    "        * To clean and prepare new data instances once your solution is live\n",
    "        * To make it easy to treat your preparation choices as hyperparameters\n",
    "    - Data cleaning\n",
    "        * Fix or remove outliers (optional)\n",
    "        * Fill in missing values or drop their rows\n",
    "    - Feature selection (optional)\n",
    "        * Drop the attributes that provide no useful information for the task\n",
    "    - Feature engineering, where appropriate:\n",
    "        * Discretize continuous features\n",
    "        * Decompose features (e.g. categorical, date/time, etc.)\n",
    "        * Add promising transformations of features (e.g. log(x), sqrt(x), x^2, etc.)\n",
    "        * Aggreagate features into promising new features\n",
    "    - Feature scaling: standardice or normalize features\n",
    "5. Explore many different models and short-list the best ones\n",
    "6. Fine-tune your models and combine them into a great solution\n",
    "7. Present your solution\n",
    "8. Launch, monitor, and maintain your system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
